# Navie Bayes Algorithm
- Introduction : 朴素的贝叶斯算法是有监督的机器学习算法，解决关于分类的问题，
该算法的优点在于简单易懂、学习效率高、在某些领域的分类问题中能够与决策树、神经网络相媲美。

- 一些数学理论：


1. 条件概率是指在事件 B 发生的情况下，事件 A 发生的概率,用 P(A|B) 表示
2. 计算公式 ： P(A|B) = P(B|A) * P(A) / P(B) 即条件概率公式。
3. 全概率公式 : 
        
        P(B) = P(B|A) * P(A) + P(B|A') * P(A')
        
        P(A|B) = P(B|A) * P(A) / P(B|A) * P(A) + P(B|A') * P(A')   

4. 贝叶斯推断 : 

                         P(B|A)
        P(A|B) = P(A) * ---------
                          P(A)
        上述公式的几个参数的定义 : 
        P(A)   : 先验概率
        P(A|B) : 后验概率
        P(B|A) / P(B) : 可能性函数，是一个调整因子
        
        所以公式可以变化为 ：后验概率 = 先验概率 * 调整因子
        
        这就是贝叶斯推断的含义:
        我们先预估一个 "先验概率"，然后加入实验结果，看这个实验到底是增强还是削弱了"先验概率"，由此得到更接近事实的"后验概率"。
        其中如果
            可能性函数 ： P(B|A) / P(B) > 1 意味着先验概率被增强，事件 A 发生的可能性变大。
            可能性函数 ： P(B|A) / P(B) == 1 意味着 B 事件无助于判断 A 事件的可能性。
            可能性函数 ： P(B|A) / P(B) < 1 意味着先验概率被削弱，事件 A 发生的可能性变小。

5. 朴素的贝叶斯推断：
        
          假设有 n 个特征：
                P(a|X) = P(X|a)P(a) = P(x1,x2,x3,...,xn|a)P(a)
          进一步拆分公式：
                P(a|X) = P(X|a)P(a)
                       = {P(x1|a)*P(x2|a)*...*P(xn|a)}P(a)


- In Action 项目实战
1. 关于 Filter 侮辱与非侮辱词汇的分类识别
